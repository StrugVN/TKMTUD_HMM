{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thống kê máy tính và Ứng dụng**  \n",
    "Học kì II, 2020 - 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center><b><font size=\"10\">ĐỒ ÁN 1</font></b></center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b><font size=\"6\"> Title </font></b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <b>Nhóm thực hiện:</b>\n",
    "    <br>Trần Minh Trí - 1712834\n",
    "    <br>Nguyễn Nhật Trường - 1712852\n",
    "    <br> ...\n",
    "    <br> ...\n",
    "    <br> ...\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Desc 1.\n",
    "* Desc 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Các thư viện hỗ trợ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "# Dùng Selenium\n",
    "import urllib.robotparser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from requests_html import HTML\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import statsmodels.api as sm\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as backend\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import callbacks\n",
    "import pickle\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "import gc\n",
    "\n",
    "from IPython.display import display, HTML, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Thu thập dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sử dụng parse HTML sử dụng `selenium`**\n",
    "\n",
    "**Nguồn dữ liệu**: Trang web [CafeF](https://s.cafef.vn/), vd cụ thể: [BHV](https://s.cafef.vn/Lich-su-giao-dich-BVH-1.chn?fbclid=IwAR0e98txe3qOw8SP_cTAVxXqeTN2CnuAiOnnLMzUXovyH-zJRZXVNBWU2sg).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check cho phép thu thập\n",
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('https://s.cafef.vn/robots.txt')\n",
    "rp.read()\n",
    "rp.can_fetch('*','https://s.cafef.vn/Lich-su-giao-dich-BVH-1.chn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_id = []\n",
    "for i in range(1, 21):\n",
    "    if i%2: row_id.append(str(i).zfill(2) + '_')\n",
    "    else: row_id.append(str(i).zfill(2) + '_alt')\n",
    "\n",
    "def get_stock_data(stock_symbol, output_file):\n",
    "    url = 'https://s.cafef.vn/Lich-su-giao-dich-' + stock_symbol + '-1.chn'    \n",
    "    \n",
    "    file = open(output_file, 'w', encoding='utf-8')\n",
    "    file.write(f'Date,Open,High,Low,Close\\n')\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path='./chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    html = HTML(html=driver.page_source)\n",
    "\n",
    "    while True:        \n",
    "        for i in row_id:\n",
    "            html = HTML(html=driver.page_source)\n",
    "            row = html.find('tr#ctl00_ContentPlaceHolder1_ctl03_rptData2_ctl' + i + 'itemTR', first=True)\n",
    "            if row:                \n",
    "                date = row.find('td.Item_DateItem', first=True).text\n",
    "                date = pd.to_datetime(date, format='%d/%m/%Y').strftime('%Y-%m-%d')\n",
    "                \n",
    "                prices = row.find('td.Item_Price10')\n",
    "                op, hi, lo, cl = prices[5].text, prices[6].text, prices[7].text, prices[1].text\n",
    "                file.write(f'{date},{op},{hi},{lo},{cl}\\n')\n",
    "\n",
    "        button = driver.find_elements(By.LINK_TEXT, '>')\n",
    "        if len(button) > 0:\n",
    "            button[0].click()\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('csv/BVH.csv'):\n",
    "    get_stock_data('BVH', 'csv/BVH.csv')\n",
    "else:\n",
    "    print('File', 'csv/BVH.csv', 'existed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sử dụng Yahoo API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, date_format='%Y-%m-%d'):\n",
    "    all_stocks = pd.read_csv(path)\n",
    "    all_stocks[const_time_col] = pd.to_datetime(all_stocks[const_time_col], format=date_format, errors='ignore')\n",
    "    all_stocks = all_stocks.dropna(axis=0)\n",
    "    all_stocks = all_stocks.set_index(const_time_col, drop=False)\n",
    "    return all_stocks\n",
    "\n",
    "\n",
    "def get_sp500_curr_stock_symbols():\n",
    "    source = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    stock_df = source[0]\n",
    "    return stock_df['Symbol'].to_list()\n",
    "\n",
    "\n",
    "def save_stock_pulled(file_name, ticket_lists, start_date, end_date, interval='1h'):\n",
    "    \"\"\"\n",
    "    The requested range [start_day, end_date] must be within:\n",
    "        - the last 730 days for '1h' interval.\n",
    "        - the last 60 days for '90m' interval\n",
    "    \"\"\"\n",
    "    final_df = pd.DataFrame()\n",
    "    attr_list = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "    for ticket in ticket_lists:\n",
    "        df_ = pdr.get_data_yahoo(ticket, start=start_date, end=end_date, interval=interval)[attr_list]\n",
    "        df_['Name'] = ticket\n",
    "        final_df = pd.concat([final_df, df_])\n",
    "\n",
    "    final_df.index = pd.to_datetime(final_df.index).strftime('%Y/%m/%dT%H:%M:%S')\n",
    "    final_df.to_csv('../data/' + file_name + '.csv', index_label='Date')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp500 = get_sp500_curr_stock_symbols()\n",
    "# save_stock_pulled('all_stocks_last_1yr', sp500, '2020-04-06', '2021-04-06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tiền xử lí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lựa chọn các thuộc tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from financial_features import *\n",
    "\n",
    "const_time_col = 'Date'\n",
    "const_target_col = 'Close'\n",
    "const_name_col = 'Name'\n",
    "# Sửa hàm này để tính ft cho HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_features(data, norm_func=None, next_t=1, re_fit=True):\n",
    "    feature_df = data[[const_time_col, const_name_col, const_target_col]].copy()\n",
    "\n",
    "    numeric_cols = data.select_dtypes(\n",
    "        include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns.tolist()\n",
    "    # for c in numeric_cols:\n",
    "    #    feature_df[c + '_proc'] = PROC(data[c])\n",
    "    feature_df['Close_proc'] = PROC(data['Close'], next_t)\n",
    "\n",
    "    feature_df['rsi'] = rsiFunc(data['Close'])  # Relative strength index\n",
    "    feature_df['MACD'] = computeMACD(data['Close'])[2]  # Moving Average Convergence/Divergence\n",
    "    feature_df['MA'] = movingAverage(data['Close'])  # feature_df['MA'] = data['Close'].rolling(period).mean()\n",
    "    feature_df['Open_Close_diff'] = data['Open'] - data['Close']\n",
    "    feature_df['High_Low_diff'] = data['High'] - data['Low']\n",
    "\n",
    "    if norm_func is not None:  # Normalize\n",
    "        scaler = copy(norm_func)\n",
    "        features = ['rsi', 'MACD', 'MA']\n",
    "\n",
    "        df = data.copy()\n",
    "        df[features] = feature_df[features]\n",
    "        if re_fit:\n",
    "            scaler.fit(df[numeric_cols + features])\n",
    "        data_norm = scaler.transform(df[numeric_cols + features])\n",
    "\n",
    "        data_norm_df = pd.DataFrame(data_norm, columns=[s + '_norm' for s in numeric_cols + features])\n",
    "        data_norm_df[const_time_col] = df.index\n",
    "        data_norm_df = data_norm_df.set_index(const_time_col)\n",
    "        data_norm_df['Open_Close_diff_norm'] = data_norm_df['Open_norm'] - data_norm_df['Close_norm']\n",
    "        data_norm_df['High_Low_diff_norm'] = data_norm_df['High_norm'] - data_norm_df['Low_norm']\n",
    "\n",
    "        feature_df = pd.concat([feature_df, data_norm_df], axis=1)\n",
    "\n",
    "        return feature_df, scaler, [s + '_norm' for s in numeric_cols + features]\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuyển dữ liệu về timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_point(data, selected_features, next_t, target_col, proc_w,\n",
    "                       norm_func=None, trans_func=None, re_fit=True):\n",
    "    data, scaler, scaler_col = cal_financial_features(data, proc_w, norm_func, next_t, re_fit)\n",
    "    if 'Close_proc' in selected_features:\n",
    "        data = data.iloc[next_t:]\n",
    "\n",
    "    X_df = data[selected_features].iloc[:-next_t].copy()\n",
    "\n",
    "    Y = []\n",
    "    y = np.array(data[target_col].tolist())\n",
    "    Price = []\n",
    "    price = np.array(data['Close'].tolist())\n",
    "    Proc = []\n",
    "    proc = np.array(data['Close_proc'].tolist())\n",
    "\n",
    "    t0_price = data['Close_norm'][0]\n",
    "\n",
    "    for i in range(0, len(data[target_col]) - next_t):\n",
    "        y_ti = i + next_t\n",
    "\n",
    "        Y.append({next_t: y[y_ti].tolist()})\n",
    "\n",
    "        # price\n",
    "        Price.append({next_t: price[y_ti].tolist()})\n",
    "\n",
    "        # bin_proc\n",
    "        next_b = np.sign(proc[y_ti].tolist())\n",
    "        if next_b == 0:\n",
    "            Proc.append({next_t: 1})\n",
    "        else:\n",
    "            Proc.append({next_t: next_b})\n",
    "\n",
    "    Y_df = pd.DataFrame(Y, index=data.index.values[:len(data[target_col]) - next_t])\n",
    "    Price_df = pd.DataFrame(Price, index=Y_df.index)\n",
    "    Proc_df = pd.DataFrame(Proc, index=Y_df.index)\n",
    "\n",
    "    if trans_func is not None:\n",
    "        transformer = copy(trans_func)\n",
    "        if re_fit:\n",
    "            transformer.fit(X_df)\n",
    "        X_transformed = transformer.transform(X_df)\n",
    "\n",
    "        cols = [i for i in range(X_transformed.shape[1])]\n",
    "        if transformer.__class__.__name__ == PCA().__class__.__name__:\n",
    "            cols = ['pca_{}'.format(i) for i in cols]\n",
    "        elif transformer.__class__.__name__ == SAX().__class__.__name__:\n",
    "            cols = X_df.columns\n",
    "\n",
    "        X_transformed_df = pd.DataFrame(X_transformed, columns=cols,\n",
    "                                        index=X_df.index)\n",
    "\n",
    "        X_df = X_transformed_df\n",
    "\n",
    "        return X_df, Y_df, Price_df, Proc_df, t0_price, scaler, scaler_col, transformer\n",
    "\n",
    "    return X_df, Y_df, Price_df, Proc_df, t0_price, scaler, scaler_col, None\n",
    "\n",
    "\n",
    "def prepare_time_window(data, selected_features, w_len, next_t, target_col, proc_w,\n",
    "                        norm_func=None, trans_func=None, re_fit=True):\n",
    "    data, scaler, scaler_col = cal_financial_features(data, proc_w, norm_func, next_t, re_fit)\n",
    "\n",
    "    if 'Close_proc' in selected_features:\n",
    "        data = data.iloc[next_t:]\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    y = np.array(data[target_col].tolist())\n",
    "    Price = []\n",
    "    price = np.array(data['Close'].tolist())\n",
    "    Proc = []\n",
    "    proc = np.array(data['Close_proc'].tolist())\n",
    "\n",
    "    t0_price = data['Close_norm'][w_len - 1]\n",
    "\n",
    "    for i in range(0, len(data[target_col]) - w_len + 1 - next_t):\n",
    "        y_ti = i + w_len - 1 + next_t\n",
    "        # Y\n",
    "        next_y = y[y_ti].tolist()\n",
    "        Y_period = {str(next_t): next_y}\n",
    "        Y.append(Y_period)\n",
    "\n",
    "        # X\n",
    "        X_period = data[i:i + w_len]\n",
    "        X_period.insert(0, 'i', range(w_len))  # 1 đoạn window_len\n",
    "        period_time = X_period.index.values[-1]\n",
    "\n",
    "        X_period = X_period[selected_features + ['i'] + [const_name_col]].pivot(index=const_name_col, columns='i')\n",
    "        X_period_dict = X_period.iloc[0].to_dict()\n",
    "        X_period_dict[const_time_col] = period_time\n",
    "        X.append(X_period_dict)\n",
    "\n",
    "        # price\n",
    "        Price.append({next_t: price[i + w_len].tolist()})\n",
    "\n",
    "        # bin_proc\n",
    "        next_b = np.sign(proc[y_ti].tolist())\n",
    "        if next_b == 0:\n",
    "            Proc.append({next_t: 1})\n",
    "        else:\n",
    "            Proc.append({next_t: next_b})\n",
    "\n",
    "    X_df = pd.DataFrame(X).set_index(const_time_col)\n",
    "    Y_df = pd.DataFrame(Y, index=X_df.index)\n",
    "    Price_df = pd.DataFrame(Price, index=X_df.index)\n",
    "    Proc_df = pd.DataFrame(Proc, index=X_df.index)\n",
    "\n",
    "    if trans_func is not None:\n",
    "        transformer = copy(trans_func)\n",
    "        if re_fit:\n",
    "            transformer.fit(X_df)\n",
    "        X_transformed = transformer.transform(X_df)\n",
    "\n",
    "        cols = [i for i in range(X_transformed.shape[1])]\n",
    "        if transformer.__class__.__name__ == PCA().__class__.__name__:\n",
    "            cols = ['pca_{}'.format(i) for i in cols]\n",
    "        elif transformer.__class__.__name__ == SAX().__class__.__name__:\n",
    "            cols = X_df.columns\n",
    "\n",
    "        X_transformed_df = pd.DataFrame(X_transformed, columns=cols,\n",
    "                                        index=X_df.index)\n",
    "\n",
    "        X_df = X_transformed_df\n",
    "\n",
    "        return X_df, Y_df, Price_df, Proc_df, t0_price, scaler, scaler_col, transformer\n",
    "\n",
    "    return X_df, Y_df, Price_df, Proc_df, t0_price, scaler, scaler_col, None\n",
    "\n",
    "\n",
    "def prepare_train_test_data(data, selected_features, comparing_stock, w_len, next_t, target_col,\n",
    "                            top_stock, proc_w, weighted_sampling=False, is_test=False,\n",
    "                            norm_func=None, trans_func=None):\n",
    "    if w_len > 1:\n",
    "        X_df, Y_df, Prices_df, Proc_df, t_0, scaler, scaler_cols, transformer = prepare_time_window(\n",
    "            data[data[const_name_col] == comparing_stock],\n",
    "            selected_features, w_len, next_t, target_col, proc_w, norm_func, trans_func, re_fit=not is_test)\n",
    "    else:\n",
    "        X_df, Y_df, Prices_df, Proc_df, t_0, scaler, scaler_cols, transformer = prepare_time_point(\n",
    "            data[data[const_name_col] == comparing_stock],\n",
    "            selected_features, next_t, target_col, proc_w, norm_func, trans_func, re_fit=not is_test)\n",
    "\n",
    "    if not is_test and top_stock is not None:\n",
    "        _scaler, _transformer = None, None\n",
    "        if norm_func is not None and norm_func.__class__.__name__ == StandardScaler().__class__.__name__:\n",
    "            _scaler = StandardScaler()\n",
    "\n",
    "        if trans_func is not None:\n",
    "            if trans_func.__class__.__name__ == PCA().__class__.__name__:\n",
    "                _transformer = PCA(n_components=3, random_state=0)\n",
    "            elif trans_func.__class__.__name__ == SAX().__class__.__name__:\n",
    "                _transformer = SAX()\n",
    "\n",
    "        for stock_name in top_stock.keys():\n",
    "            stock_df = data[data[const_name_col] == stock_name]\n",
    "            min_data_point = 1\n",
    "            if _transformer.__class__.__name__ == PCA().__class__.__name__:\n",
    "                min_data_point += 3\n",
    "            if stock_df.empty or stock_df.shape[0] < w_len + next_t + min_data_point:\n",
    "                continue\n",
    "            if w_len > 1:\n",
    "                sim_stock_X, sim_stock_Y, sim_stock_Prices, sim_stock_Proc, _, _, _, _ = \\\n",
    "                    prepare_time_window(stock_df, selected_features, w_len, next_t,\n",
    "                                        target_col, proc_w, _scaler, _transformer)\n",
    "            else:\n",
    "                sim_stock_X, sim_stock_Y, sim_stock_Prices, sim_stock_Proc, _, _, _, _ = \\\n",
    "                    prepare_time_point(stock_df, selected_features, next_t,\n",
    "                                       target_col, proc_w, _scaler, _transformer)\n",
    "\n",
    "            if weighted_sampling:\n",
    "                np.random.seed(0)\n",
    "                msk = (np.random.rand(len(sim_stock_X)) < top_stock[stock_name])\n",
    "                sim_stock_X = sim_stock_X[msk]\n",
    "                sim_stock_Y = sim_stock_Y[msk]\n",
    "                sim_stock_Prices = sim_stock_Prices[msk]\n",
    "                sim_stock_Proc = sim_stock_Proc[msk]\n",
    "\n",
    "            X_df = pd.concat([sim_stock_X, X_df])\n",
    "            Y_df = pd.concat([sim_stock_Y, Y_df])\n",
    "            Prices_df = pd.concat([sim_stock_Prices, Prices_df])\n",
    "            Proc_df = pd.concat([sim_stock_Proc, Proc_df])\n",
    "\n",
    "    return X_df, Y_df, Prices_df[next_t], Proc_df[next_t].to_numpy(), t_0, scaler, scaler_cols, transformer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "other-env-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
