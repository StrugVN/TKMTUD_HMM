{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thống kê máy tính và Ứng dụng**  \n",
    "Học kì II, 2020 - 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center><b><font size=\"10\">ĐỒ ÁN 1</font></b></center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b><font size=\"6\"> Title </font></b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <b>Nhóm thực hiện:</b>\n",
    "    <br>Trần Minh Trí - 1712834\n",
    "    <br>Nguyễn Nhật Trường - 1712852\n",
    "    <br> ...\n",
    "    <br> ...\n",
    "    <br> ...\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Desc 1.\n",
    "* Desc 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Các thư viện hỗ trợ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import statsmodels.api as sm\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as backend\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import callbacks\n",
    "import pickle\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "import gc\n",
    "\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "from copy import copy\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from financial_features import *\n",
    "\n",
    "const_time_col = 'Date'\n",
    "const_target_col = 'Close'\n",
    "const_name_col = 'Name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Thu thập dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sử dụng Yahoo API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, date_format='%Y-%m-%d'):\n",
    "    all_stocks = pd.read_csv(path)\n",
    "    all_stocks[const_time_col] = pd.to_datetime(all_stocks[const_time_col], format=date_format, errors='ignore')\n",
    "    all_stocks = all_stocks.dropna(axis=0)\n",
    "    all_stocks = all_stocks.set_index(const_time_col, drop=False)\n",
    "    return all_stocks\n",
    "\n",
    "\n",
    "def get_sp500_curr_stock_symbols():\n",
    "    source = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    stock_df = source[0]\n",
    "    return stock_df['Symbol'].to_list()\n",
    "\n",
    "\n",
    "def save_stock_pulled(file_name, ticket_lists, start_date, end_date, interval='1d'):\n",
    "    \"\"\"\n",
    "    The requested range [start_day, end_date] must be within:\n",
    "        - the last 730 days for '1h' interval.\n",
    "        - the last 60 days for '90m' interval\n",
    "    \"\"\"\n",
    "    final_df = pd.DataFrame()\n",
    "    attr_list = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "    for ticket in ticket_lists:\n",
    "        df_ = pdr.get_data_yahoo(ticket, start=start_date, end=end_date, interval=interval)[attr_list]\n",
    "        df_['Name'] = ticket\n",
    "        final_df = pd.concat([final_df, df_])\n",
    "\n",
    "    final_df.index = pd.to_datetime(final_df.index).strftime('%Y/%m/%dT%H:%M:%S')\n",
    "    final_df.to_csv(file_name + '.csv', index_label='Date')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp500 = get_sp500_curr_stock_symbols()\n",
    "#save_stock_pulled('s&p500', sp500, '2005-01-01', '2021-05-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data('s&p500.csv', date_format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>99.714714</td>\n",
       "      <td>100.040039</td>\n",
       "      <td>96.376373</td>\n",
       "      <td>96.491493</td>\n",
       "      <td>15321663.0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>98.798798</td>\n",
       "      <td>101.921921</td>\n",
       "      <td>97.827827</td>\n",
       "      <td>101.456459</td>\n",
       "      <td>31656712.0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>100.800804</td>\n",
       "      <td>101.566566</td>\n",
       "      <td>96.836838</td>\n",
       "      <td>97.347343</td>\n",
       "      <td>27484288.0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>96.821823</td>\n",
       "      <td>98.548546</td>\n",
       "      <td>96.211212</td>\n",
       "      <td>96.851852</td>\n",
       "      <td>16456727.0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>97.637634</td>\n",
       "      <td>98.048050</td>\n",
       "      <td>93.953957</td>\n",
       "      <td>94.369370</td>\n",
       "      <td>20753426.0</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date        Open        High        Low       Close  \\\n",
       "Date                                                                   \n",
       "2004-12-31 2004-12-31   99.714714  100.040039  96.376373   96.491493   \n",
       "2005-01-03 2005-01-03   98.798798  101.921921  97.827827  101.456459   \n",
       "2005-01-04 2005-01-04  100.800804  101.566566  96.836838   97.347343   \n",
       "2005-01-05 2005-01-05   96.821823   98.548546  96.211212   96.851852   \n",
       "2005-01-06 2005-01-06   97.637634   98.048050  93.953957   94.369370   \n",
       "\n",
       "                Volume   Name  \n",
       "Date                           \n",
       "2004-12-31  15321663.0  GOOGL  \n",
       "2005-01-03  31656712.0  GOOGL  \n",
       "2005-01-04  27484288.0  GOOGL  \n",
       "2005-01-05  16456727.0  GOOGL  \n",
       "2005-01-06  20753426.0  GOOGL  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googl = data[data['Name'] == 'GOOGL']\n",
    "googl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tiền xử lí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Lựa chọn các thuộc tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sửa hàm này để tính ft cho HMM\n",
    "def cal_features(data, norm_func=None, next_t=1, re_fit=True):\n",
    "    feature_df = data[[const_time_col, const_name_col, const_target_col]].copy()\n",
    "\n",
    "    numeric_cols = data.select_dtypes(\n",
    "        include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns.tolist()\n",
    "\n",
    "    feature_df['Close_proc'] = PROC(data['Close'], next_t) # Luôn giữ\n",
    "    feature_df['frac_change'] = (data['Close'] - data['Open'])/data['Open']\n",
    "    feature_df['frac_high'] = (data['High'] - data['Open'])/data['Open']\n",
    "    feature_df['frac_low'] = (data['Open'] - data['Low'])/data['Open']\n",
    "    \n",
    "\n",
    "    #feature_df['rsi'] = rsiFunc(data['Close'])  # Relative strength index\n",
    "    #feature_df['MACD'] = computeMACD(data['Close'])[2]  # Moving Average Convergence/Divergence\n",
    "    #feature_df['MA'] = movingAverage(data['Close'])  # feature_df['MA'] = data['Close'].rolling(period).mean()\n",
    "    #feature_df['Open_Close_diff'] = data['Open'] - data['Close']\n",
    "    #feature_df['High_Low_diff'] = data['High'] - data['Low']\n",
    "    \n",
    "    return feature_df\n",
    "    # Not norm for now\n",
    "\n",
    "    if norm_func is not None:  # Normalize\n",
    "        scaler = copy(norm_func)\n",
    "        features = ['rsi', 'MACD', 'MA'] # Ft. to norm\n",
    "\n",
    "        df = data.copy()\n",
    "        df[features] = feature_df[features]\n",
    "        if re_fit:\n",
    "            scaler.fit(df[numeric_cols + features])\n",
    "        data_norm = scaler.transform(df[numeric_cols + features])\n",
    "\n",
    "        data_norm_df = pd.DataFrame(data_norm, columns=[s + '_norm' for s in numeric_cols + features])\n",
    "        data_norm_df[const_time_col] = df.index\n",
    "        data_norm_df = data_norm_df.set_index(const_time_col)\n",
    "        data_norm_df['Open_Close_diff_norm'] = data_norm_df['Open_norm'] - data_norm_df['Close_norm']\n",
    "        data_norm_df['High_Low_diff_norm'] = data_norm_df['High_norm'] - data_norm_df['Low_norm']\n",
    "\n",
    "        feature_df = pd.concat([feature_df, data_norm_df], axis=1)\n",
    "\n",
    "        return feature_df, scaler, [s + '_norm' for s in numeric_cols + features]\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_proc</th>\n",
       "      <th>frac_change</th>\n",
       "      <th>frac_high</th>\n",
       "      <th>frac_low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>96.491493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.032324</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.033479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>101.456459</td>\n",
       "      <td>0.051455</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.031611</td>\n",
       "      <td>0.009828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>97.347343</td>\n",
       "      <td>-0.040501</td>\n",
       "      <td>-0.034260</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.039325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>96.851852</td>\n",
       "      <td>-0.005090</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.017834</td>\n",
       "      <td>0.006307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>94.369370</td>\n",
       "      <td>-0.025632</td>\n",
       "      <td>-0.033473</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.037728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date   Name       Close  Close_proc  frac_change  frac_high  \\\n",
       "Date                                                                           \n",
       "2004-12-31 2004-12-31  GOOGL   96.491493    0.000000    -0.032324   0.003263   \n",
       "2005-01-03 2005-01-03  GOOGL  101.456459    0.051455     0.026900   0.031611   \n",
       "2005-01-04 2005-01-04  GOOGL   97.347343   -0.040501    -0.034260   0.007597   \n",
       "2005-01-05 2005-01-05  GOOGL   96.851852   -0.005090     0.000310   0.017834   \n",
       "2005-01-06 2005-01-06  GOOGL   94.369370   -0.025632    -0.033473   0.004203   \n",
       "\n",
       "            frac_low  \n",
       "Date                  \n",
       "2004-12-31  0.033479  \n",
       "2005-01-03  0.009828  \n",
       "2005-01-04  0.039325  \n",
       "2005-01-05  0.006307  \n",
       "2005-01-06  0.037728  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googl_ft = cal_features(googl, norm_func=None, next_t=1, re_fit=True)\n",
    "googl_ft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Chuyển dữ liệu về timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_point(data, selected_features, next_t, target_col, norm_func=None, re_fit=True):\n",
    "    data, scaler, scaler_col = cal_financial_features(data, norm_func, next_t, re_fit)\n",
    "    if 'Close_proc' in selected_features:\n",
    "        data = data.iloc[next_t:]\n",
    "\n",
    "    X_df = data[selected_features].iloc[:-next_t].copy()\n",
    "\n",
    "    Y = []\n",
    "    y = np.array(data[target_col].tolist())\n",
    "    Price = []\n",
    "    price = np.array(data['Close'].tolist())\n",
    "    Proc = []\n",
    "    proc = np.array(data['Close_proc'].tolist())\n",
    "\n",
    "    t0_price = data['Close_norm'][0]\n",
    "\n",
    "    for i in range(0, len(data[target_col]) - next_t):\n",
    "        y_ti = i + next_t\n",
    "\n",
    "        Y.append({next_t: y[y_ti].tolist()})\n",
    "\n",
    "        # price\n",
    "        Price.append({next_t: price[y_ti].tolist()})\n",
    "\n",
    "        # bin_proc\n",
    "        next_b = np.sign(proc[y_ti].tolist())\n",
    "        if next_b == 0:\n",
    "            Proc.append({next_t: 1})\n",
    "        else:\n",
    "            Proc.append({next_t: next_b})\n",
    "\n",
    "    Y_df = pd.DataFrame(Y, index=data.index.values[:len(data[target_col]) - next_t])\n",
    "    Price_df = pd.DataFrame(Price, index=Y_df.index)\n",
    "    Proc_df = pd.DataFrame(Proc, index=Y_df.index)\n",
    "\n",
    "    return X_df, Y_df, Price_df, Proc_df, t0_price, scaler, scaler_col, None\n",
    "\n",
    "\n",
    "def prepare_time_window(data, selected_features, w_len, next_t, target_col, norm_func=None, re_fit=True):\n",
    "    data, scaler, scaler_col = cal_financial_features(data, norm_func, next_t, re_fit)\n",
    "\n",
    "    if 'Close_proc' in selected_features:\n",
    "        data = data.iloc[next_t:]\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    y = np.array(data[target_col].tolist())\n",
    "    Price = []\n",
    "    price = np.array(data['Close'].tolist())\n",
    "    Proc = []\n",
    "    proc = np.array(data['Close_proc'].tolist())\n",
    "\n",
    "    t0_price = data['Close_norm'][w_len - 1]\n",
    "\n",
    "    for i in range(0, len(data[target_col]) - w_len + 1 - next_t):\n",
    "        y_ti = i + w_len - 1 + next_t\n",
    "        # Y\n",
    "        next_y = y[y_ti].tolist()\n",
    "        Y_period = {str(next_t): next_y}\n",
    "        Y.append(Y_period)\n",
    "\n",
    "        # X\n",
    "        X_period = data[i:i + w_len]\n",
    "        X_period.insert(0, 'i', range(w_len))  # 1 đoạn window_len\n",
    "        period_time = X_period.index.values[-1]\n",
    "\n",
    "        X_period = X_period[selected_features + ['i'] + [const_name_col]].pivot(index=const_name_col, columns='i')\n",
    "        X_period_dict = X_period.iloc[0].to_dict()\n",
    "        X_period_dict[const_time_col] = period_time\n",
    "        X.append(X_period_dict)\n",
    "\n",
    "        # price\n",
    "        Price.append({next_t: price[i + w_len].tolist()})\n",
    "\n",
    "        # bin_proc\n",
    "        next_b = np.sign(proc[y_ti].tolist())\n",
    "        if next_b == 0:\n",
    "            Proc.append({next_t: 1})\n",
    "        else:\n",
    "            Proc.append({next_t: next_b})\n",
    "\n",
    "    X_df = pd.DataFrame(X).set_index(const_time_col)\n",
    "    Y_df = pd.DataFrame(Y, index=X_df.index)\n",
    "    Price_df = pd.DataFrame(Price, index=X_df.index)\n",
    "    Proc_df = pd.DataFrame(Proc, index=X_df.index)\n",
    "\n",
    "    return X_df, Y_df, Price_df, Proc_df, t0_price, scaler, scaler_col, None\n",
    "\n",
    "\n",
    "def prepare_train_test_data(data, selected_features, comparing_stock, w_len, next_t, target_col, norm_func=None):\n",
    "    if w_len > 1:\n",
    "        X_df, Y_df, Prices_df, Proc_df, t_0, scaler, scaler_cols, transformer = prepare_time_window(\n",
    "            data[data[const_name_col] == comparing_stock],\n",
    "            selected_features, w_len, next_t, target_col, proc_w, norm_func, trans_func, re_fit=not is_test)\n",
    "    else:\n",
    "        X_df, Y_df, Prices_df, Proc_df, t_0, scaler, scaler_cols, transformer = prepare_time_point(\n",
    "            data[data[const_name_col] == comparing_stock],\n",
    "            selected_features, next_t, target_col, proc_w, norm_func, trans_func, re_fit=not is_test)\n",
    "\n",
    "    return X_df, Y_df, Prices_df[next_t], Proc_df[next_t].to_numpy(), t_0, scaler, scaler_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mô hình hóa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Cài đặt mô hình HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Chia tập dữ liệu train - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data('data/' + data_name + '.csv')\n",
    "stock = 'Tên stock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_set(data, stock, ratio):\n",
    "    stock_times = data[data[const_name_col] == stock][const_time_col].tolist()  # List of date\n",
    "\n",
    "    train_len = int(len(stock_times) * ratio)\n",
    "\n",
    "    train_start, train_end = stock_times[0], stock_times[train_len]\n",
    "    test_start, test_end = stock_times[train_len + 1], stock_times[-1]\n",
    "    \n",
    "    train_df = data[(train_start <= data[const_time_col]) & (data[const_time_col] < train_end)]\n",
    "    \n",
    "    test_df = data[(test_start <= data[const_time_col])& (data[const_time_col] < test_end)]\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train-test set\n",
    "df, test_df = split_train_test_set(data, stock, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Trading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_short_profit_evaluation(curr_price, predicted_price):\n",
    "    is_long = None\n",
    "    profit = 0\n",
    "    last_buy = 0\n",
    "    profits = []\n",
    "    position = 0\n",
    "    start = curr_price[0]\n",
    "    count = 0\n",
    "    for i in range(len(curr_price)):\n",
    "        # go long\n",
    "        if predicted_price[i] > 0:\n",
    "            # first time\n",
    "            if is_long is None:\n",
    "                last_buy = curr_price[i]\n",
    "                is_long = True\n",
    "            # if short position - close it and go long\n",
    "            elif not is_long:\n",
    "                profit = profit + (last_buy - curr_price[i])\n",
    "                position = profit\n",
    "                last_buy = curr_price[i]\n",
    "                is_long = True\n",
    "                count += 1\n",
    "            elif is_long:\n",
    "                position = profit + (curr_price[i] - last_buy)\n",
    "\n",
    "        # go short\n",
    "        if predicted_price[i] < 0:\n",
    "            # first time\n",
    "            if is_long is None:\n",
    "                last_buy = curr_price[i]\n",
    "                is_long = False\n",
    "            # if long position - close it and go short\n",
    "            elif is_long:\n",
    "                profit = profit + (curr_price[i] - last_buy)\n",
    "                position = profit\n",
    "                last_buy = curr_price[i]\n",
    "                is_long = False\n",
    "                count += 1\n",
    "            elif not is_long:\n",
    "                position = profit + (last_buy - curr_price[i])\n",
    "\n",
    "        profits.append(position)\n",
    "\n",
    "    # Close final position\n",
    "    profit = position\n",
    "    count += 1\n",
    "\n",
    "    return profit, profits, profit * 100 / start, count / len(curr_price)\n",
    "\n",
    "\n",
    "def buy_low_sell_high(curr_price, predicted_price):\n",
    "    is_long = False\n",
    "    profit = 0\n",
    "    last_buy = 0\n",
    "    profits = []\n",
    "    position = 0\n",
    "    start = curr_price[0]\n",
    "    count = 0\n",
    "    for i in range(len(curr_price)):\n",
    "        # buy low\n",
    "        if predicted_price[i] > 0:\n",
    "            if is_long is False:\n",
    "                last_buy = curr_price[i]\n",
    "                is_long = True\n",
    "            elif is_long:\n",
    "                position = profit + (curr_price[i] - last_buy)\n",
    "\n",
    "        # sell high\n",
    "        if predicted_price[i] < 0:\n",
    "            if is_long:\n",
    "                profit = profit + (curr_price[i] - last_buy)\n",
    "                position = profit\n",
    "                is_long = False\n",
    "\n",
    "        profits.append(position)\n",
    "\n",
    "    # Close final position\n",
    "    profit = position\n",
    "    count += 1\n",
    "\n",
    "    return profit, profits, profit * 100 / start, count / len(curr_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Tìm cấu hình tốt nhất"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tạo tổ hợp cấu hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_test_param(target_col, selected_features, next_t,\n",
    "                      window_len, model_name, eval_result_path, norm_func, n_fold):\n",
    "    base_dict = {\n",
    "        'target_col': target_col,  # \n",
    "        'next_t': next_t,  #\n",
    "        'selected_features': selected_features,  #\n",
    "        'window_len': window_len,  #\n",
    "        'model_name': model_name,  # hmm\n",
    "        'n_fold': n_fold,  # cố định\n",
    "        'eval_result_path': eval_result_path,  # cố định\n",
    "        'norm_func': norm_func,  # có thể ko cần?\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*base_dict.items())\n",
    "    permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    return permutations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\n",
    "    'target_col': ['Close_norm',\n",
    "                   'Close_proc'],\n",
    "    'next_t': [1],\n",
    "    'selected_features': [\n",
    "        ['Close_norm'], ['Close_proc'],\n",
    "        ['Close_norm', 'Close_proc', 'rsi_norm', 'MACD_norm',\n",
    "         'Open_Close_diff_norm', 'High_Low_diff_norm', 'Volume_norm'],\n",
    "        ['Close_norm', 'rsi_norm', 'MA_norm']\n",
    "    ],\n",
    "    'window_len': [1, 3, 7, 15, 30],\n",
    "    'model_name': [''],\n",
    "    'n_fold': [5],\n",
    "    'eval_result_path': [''],\n",
    "    'norm_func': [StandardScaler()],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(target_col, next_t, selected_features,\n",
    "            window_len, eval_result_path, n_fold, norm_func):\n",
    "    model_name = 'HMM'\n",
    "    \n",
    "    # Tạo k folds\n",
    "    target_stock_dates = df[df[const_name_col] == stock][const_time_col]\n",
    "    folds_df = []\n",
    "\n",
    "    threshold = int(len(target_stock_dates) / (n_fold + 1))\n",
    "    for i in range(1, n_fold):\n",
    "        fold_time = target_stock_dates[:(i + 1) * threshold - 1]\n",
    "        _folds_time.append((i + 1) * threshold - 1)\n",
    "        fold_df_ = df[df[const_time_col].isin(fold_time)]\n",
    "        folds_df.append(fold_df_)\n",
    "    folds_df.append(df[df[const_time_col].isin(target_stock_dates)])\n",
    "    \n",
    "    for _df in folds_df:\n",
    "        # Split train-valid set\n",
    "\n",
    "        train_df, test_df = split_train_test_set(_df, stock, 0.8)\n",
    "\n",
    "        train_X, train_Y, train_price_Y, bin_train_Y, _, scaler, scaler_cols, transformer = \\\n",
    "                        prepare_train_test_data(train_df, selected_features, stock, window_len, next_t,\n",
    "                                                target_col, norm_func=norm_func)\n",
    "\n",
    "        test_X, test_Y, test_price_Y, bin_test_Y, test_t0_price, _, _, _ = \\\n",
    "                        prepare_train_test_data(test_df, selected_features, stock, window_len, next_t, \n",
    "                                                target_col, norm_func=scaler)\n",
    "\n",
    "\n",
    "        # Đổi để chạy với HMM\n",
    "\n",
    "        # HMM ra kết quả regression hay classification?\n",
    "        is_classifier = '?'\n",
    "        if not is_classifier:\n",
    "            model = fit_model_funcs[model_name](train_X, train_Y)\n",
    "            pred_Y = model.predict(test_X)\n",
    "        else:\n",
    "            train_Y_ = np.array(bin_train_Y)\n",
    "\n",
    "            model = fit_model_funcs[model_name](train_X, train_Y_)\n",
    "\n",
    "            pred_Y = model.predict(test_X)\n",
    "\n",
    "        # Evaluation\n",
    "        evals = dict()\n",
    "        if not is_classifier:\n",
    "            if 'proc' not in target_col:\n",
    "                inverted_pred_Y = inverse_scaling(target_col, pred_Y, scaler_cols, scaler)\n",
    "                evals['rmse'] = np.sqrt(mean_squared_error(test_Y, pred_Y))\n",
    "\n",
    "                bin_pred_Y = [np.sign(pred_Y[0] - test_t0_price)]\n",
    "                for i in range(1, len(pred_Y)):\n",
    "                    bin_pred_Y.append(np.sign(pred_Y[i] - test_Y.iloc[:, 0][i - 1]))\n",
    "                bin_pred_Y = np.array([1 if x == 0 else x for x in bin_pred_Y])\n",
    "            else:\n",
    "                evals['rmse'] = np.sqrt(mean_squared_error(test_Y, pred_Y))\n",
    "\n",
    "                bin_pred_Y = [x if x != 0 else 1 for x in np.sign(pred_Y)]\n",
    "\n",
    "        else:\n",
    "            bin_pred_Y = pred_Y\n",
    "\n",
    "        inverted_t0_price = inverse_scaling('Close_norm', [test_t0_price], scaler_cols, scaler).tolist()[0]\n",
    "        curr_price = test_price_Y.tolist()[:-1]\n",
    "        curr_price.insert(0, inverted_t0_price)\n",
    "\n",
    "        evals[\"long_short_profit\"], profits, evals[\"profit_%\"], evals[\"order_count\"] = \\\n",
    "            long_short_profit_evaluation(curr_price, bin_pred_Y)\n",
    "\n",
    "        evals[\"sharpe_ratio\"] = np.mean(profits) / (np.std([profits]) + 0.0001)\n",
    "\n",
    "        evals[\"BLSH_profit\"], long_profits, evals[\"L_profit_%\"], evals[\"L_order_count\"] = \\\n",
    "            buy_low_sell_high(curr_price, bin_pred_Y)\n",
    "\n",
    "        evals[\"L_sharpe_ratio\"] = np.mean(long_profits) / (np.std([long_profits]) + 0.0001)\n",
    "\n",
    "        evals['accuracy_score'] = accuracy_score(bin_test_Y, bin_pred_Y)\n",
    "        evals['f1_score'] = f1_score(bin_test_Y, bin_pred_Y, average='macro')\n",
    "\n",
    "        if len(np.unique(bin_pred_Y)) < 2:\n",
    "            if np.unique(bin_pred_Y)[0] > 0:\n",
    "                s = 'U'\n",
    "            else:\n",
    "                s = 'D'\n",
    "            evals['folds result'] = s\n",
    "        elif evals[\"long_short_profit\"] > 0:\n",
    "            evals['folds result'] = '+'\n",
    "        else:\n",
    "            evals['folds result'] = '-'\n",
    "\n",
    "        print({key: round(evals[key], 3) if not isinstance(evals[key], str) else evals[key] for key in evals})\n",
    "        evals_list.append(evals)\n",
    "\n",
    "    # Save evaluation\n",
    "    eval_df = pd.DataFrame(evals_list)\n",
    "    \"\"\"\n",
    "    No. of features, selected_features, sim_func, fix_len_func, k stock, window_len, next_t, model, \n",
    "     mean_accuracy, std_accuracy, mean_f1, std_f1, mean_mse, std_mse, mean_sharp_ratio, mean_profit, std_profit\n",
    "    \"\"\"\n",
    "    text_selected_ft = str(selected_features).replace(',', ';')\n",
    "\n",
    "    mean_accuracy, std_accuracy = np.round((np.mean(eval_df['accuracy_score']), np.std(eval_df['accuracy_score'])), 4)\n",
    "    mean_f1, std_f1 = np.round((np.mean(eval_df['f1_score']), np.std(eval_df['f1_score'])), 4)\n",
    "    if not is_classifier:\n",
    "        mean_mse, std_mse = np.round((np.mean(eval_df['rmse']), np.std(eval_df['rmse'])), 3)\n",
    "    else:\n",
    "        mean_mse, std_mse = 'NaN', 'NaN'\n",
    "\n",
    "    mean_sharpe_ratio, mean_profit = np.round((np.mean(eval_df['sharpe_ratio']),\n",
    "                                               np.mean(eval_df['long_short_profit'])), 3)\n",
    "    mean_profit_pc, mean_order_count = np.round((np.mean(eval_df['profit_%']),\n",
    "                                                 np.mean(eval_df['order_count'])), 3)\n",
    "\n",
    "    mean_L_sharpe_ratio, mean_L_profit = np.round((np.mean(eval_df['L_sharpe_ratio']),\n",
    "                                                   np.mean(eval_df['BLSH_profit'])), 3)\n",
    "    mean_L_profit_pc, mean_L_order_count = np.round((np.mean(eval_df['L_profit_%']),\n",
    "                                                     np.mean(eval_df['L_order_count'])), 3)\n",
    "\n",
    "    folds_result = ''.join(eval_df['folds result'])\n",
    "\n",
    "    if not os.path.isfile(eval_result_path):\n",
    "        with open(eval_result_path, \"w\") as file:\n",
    "            file.write(\"No. of features, selected_features, window_len, \"\n",
    "                       \"next_t, model, target_col, mean_accuracy, std_accuracy, \"\n",
    "                       \"mean_f1, std_f1, mean_rmse, std_rmse, \"\n",
    "                       \"folds_result, mean_orders_count_per_hours, mean_sharpe_ratio, mean_profit_%, mean_profit, \"\n",
    "                       \"mean_L_orders_count_per_hours, mean_L_sharpe_ratio, mean_L_profit_%, mean_L_profit\\n\")\n",
    "            file.close()\n",
    "\n",
    "    with open(eval_result_path, \"a\") as file:\n",
    "        file.write(\"{0}, {1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}, {9}, {10}, {11}, {12}, {13}, {14}, {15}, {16}, {17}, \"\n",
    "                   \"{18}, {19}, {20}\\n \"\n",
    "                   .format(len(selected_features), text_selected_ft, window_len, next_t, model_name, target_col, mean_accuracy,\n",
    "                           std_accuracy, mean_f1, std_f1, mean_mse, std_mse,\n",
    "                           folds_result, mean_order_count, mean_sharpe_ratio, mean_profit_pc, mean_profit,\n",
    "                           mean_L_order_count, mean_L_sharpe_ratio, mean_L_profit_pc, mean_L_profit))\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate Experience\n",
    "    ts = time.time()\n",
    "    exps = expand_test_param(**test)\n",
    "    count, exp_len = 1, len(exps)\n",
    "    print(' ============= Total: {0} - {1} ============= '.format(exp_len, data_name))\n",
    "    for d in exps:\n",
    "        es = time.time()\n",
    "        print('\\nRunning test param: {0}/{1}'.format(count, exp_len))\n",
    "        print(d)\n",
    "        count += 1\n",
    "        if (d['selected_features'] == ['Close_proc'] and d['target_col'] == 'Close_norm') \\\n",
    "                or (d['trans_func'].__class__.__name__ == PCA().__class__.__name__ and len(d['selected_features']) < 4):\n",
    "            print('     Skipped')\n",
    "            continue\n",
    "\n",
    "        run_exp(**d)\n",
    "\n",
    "        print('Elapsed: ', np.round(time.time() - es, 2), 's, total: ', np.round((time.time() - ts) / 60, 2), 'm', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "other-env-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
